import json, openai, os, importlib, streamlit as st
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸° ë° OpenAI API Key ì„¤ì •
load_dotenv()
OPEN_API_KEY = os.getenv("OPEN_API_KEY")
client = openai.OpenAI(api_key=OPEN_API_KEY)

# í•¨ìˆ˜ ì„¤ì •
tools = [{
    "type": "function",
    "name": "check_black_list",
    "description": "ì‚¬ìš©ìë¡œë¶€í„° ì•…ì„± URL ê´€ë ¨ íŒë‹¨ ì§ˆë¬¸ì„ ë°›ìœ¼ë©´ MLëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì•…ì„± URL íŒë‹¨ê²°ê³¼ë¥¼ ë°›ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.",
    "parameters": {
        "type": "object",
        "properties": {
            "url": {"type": "string"}
        },
        "required": ["url"],
        "additionalProperties": False
    },
    "strict": True
},
{
    "type": "web_search_preview"
}
]

def function_call(calls):
    result = []
    for call in calls:
        if call.type != "function_call":
            continue   
        try :
            result.append(call)
            function_modules = importlib.import_module("module")
            function_name = call.name
            func = getattr(function_modules, function_name)
            function_args = json.loads(call.arguments)
            output = func(**function_args)
            result.append({
                "call_id": call.call_id,
                "type": "function_call_output",
                "output": str(output)
            })

        except Exception as e:
            result.append({
                "call_id": call.call_id,
                "type": "function_call_output",
                "output": str(e)
            })
    return result

# Streamlit UI
st.title('PhishGuard Chat')
st.text('ì•…ì„± URLì„ íŒë³„í•˜ê³  ì•ˆì „í•œ ëŒ€ì•ˆì„ ì•ˆë‚´í•´ì£¼ëŠ” AI ë³´ì•ˆ ì±—ë´‡ ì„œë¹„ìŠ¤ê°€ ì˜¤í”ˆë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ‰')

# ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
if 'messages' not in st.session_state :
    st.session_state.messages = []

# ê¸°ì¡´ ë©”ì„¸ì§€ ì¶œë ¥
for msg in st.session_state.messages :
    with st.chat_message(msg['role']) :
        st.markdown(msg['content'])

# ì‚¬ìš©ì ì…ë ¥
user_prompt = st.chat_input("ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?")

# GPT ì‘ë‹µ ì²˜ë¦¬
if user_prompt :
    st.session_state.messages.append({'role' : 'user', 'content' : user_prompt})
    with st.chat_message('user') :
        st.markdown(user_prompt)

    context = [{
        "role" : "system",
        "content" : "ì•…ì„±ì½”ë“œì— ëŒ€í•œ ì§ˆë¬¸ì´ ë“¤ì–´ì˜¤ë©´ Function callì„ ì´ìš©í•´ ì‘ë‹µì„ ë°›ì•„ì•¼ í•©ë‹ˆë‹¤.\
        1ì´ë©´ ì•…ì„± URLì´ë©° 0ì´ë©´ ì •ìƒ URLì…ë‹ˆë‹¤. ì¶”ê°€ë¡œ URLì´ ì•…ì„±ì´ë©´ ì‚¬ìš©ìê°€ ë³´ë‚¸ ë„ë©”ì¸ì„ í†µí•´\
        ì‚¬ìš©ìì˜ URL ì§„ì…ëª©ì ì„ ìœ ì¶”í•˜ê³  Websearchë¥¼ í†µí•´ ëŒ€ì•ˆì‚¬ì´íŠ¸ë¥¼ 3~4ê°œì˜ URLê³¼ í•¨ê»˜ ì œì‹œí•´ì¤ë‹ˆë‹¤."
    }]
    context.append({'role' : 'user', 'content' : user_prompt})
    response = client.responses.create(
        model="gpt-4o",
        input=context,
        tools=tools,
        tool_choice="auto"
    )

    # Function Call ì²˜ë¦¬
    answer = function_call(response.output)
    context.extend(answer)

    final_response = client.responses.create(
        model="gpt-4o",
        input=context,
        tools=tools,
        tool_choice="auto")

    # AI ì‘ë‹µ ì¶œë ¥
    with st.chat_message('assistant') :
        st.markdown(final_response.output_text)

    st.session_state.messages.append({
        'role' : 'assistant',
        'content' : final_response.output_text
    })

